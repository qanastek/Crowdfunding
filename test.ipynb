{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Load compressed HD5 file...\n"
     ]
    }
   ],
   "source": [
    "import lux\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import strip_accents_unicode\n",
    "\n",
    "DATA_PROJECTS_FILE_CSV = \"data/projects.csv\"\n",
    "DATA_PROJECTS_FILE_H5 = \"data/projects.h5\"\n",
    "DATA_PROJECTS_URL = 'https://filesender.renater.fr/?s=download&token=2f5ed948-6e35-4bf1-88ed-7ab5dd0411b9'\n",
    "\n",
    "def load(path, cache=False):\n",
    "    # Reload previously processed dataset, if available\n",
    "    if (os.path.isfile(path)):\n",
    "        print('> Load compressed HD5 file...')\n",
    "        df = pd.read_hdf(path, 'data', mode='r')\n",
    "        return df\n",
    "\n",
    "    # Download CSV file, if necessary\n",
    "    # if not os.path.isfile(DATA_PROJECTS_FILE_CSV):\n",
    "    #     self.__download_data(DATA_PROJECTS_FILE_CSV)\n",
    "\n",
    "    # Read original CSV file\n",
    "    print(\"> Loading from raw CSV file...\")\n",
    "    df = pd.read_csv(DATA_PROJECTS_FILE_CSV, encoding='Windows-1252', na_values=[None], parse_dates=['start_date','end_date'], date_parser=self.dateparse)\n",
    "\n",
    "    # Preprocess original dataset\n",
    "    print(\"> Preprocessing...\")\n",
    "    print('> Convert textual columns to \\'str\\'...')\n",
    "    labels = [\n",
    "        'id',\n",
    "    ]\n",
    "    for label in labels:\n",
    "        df[label] = df.loc[df[label].notna(), label].astype(str)\n",
    "\n",
    "    print('> Normalizing string columns...')\n",
    "    for label, content in df.select_dtypes(object).iteritems():\n",
    "        df[label] = df[label].apply(lambda x: strip_accents_unicode(str(x).upper().strip()) if not str(x) in (None, 'nan') else None)\n",
    "        df.loc[(df[label] == ''), label] = None\n",
    "        df[label].replace('\\s+', ' ', regex=True, inplace=True)\n",
    "    \n",
    "    # Save the DataFrame in HDF5 for faster reload.\n",
    "    print('> Save compressed and processed DataFrame...')\n",
    "    df.to_hdf(path, key='data', complevel=9)\n",
    "\n",
    "    return df\n",
    "\n",
    "df:DataFrame = load(DATA_PROJECTS_FILE_H5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'name', 'start_date', 'end_date'], axis=1)\n",
    "# df.info()\n",
    "# df = pd.read_csv(\"https://github.com/lux-org/lux-datasets/blob/master/data/hpi_cleaned.csv?raw=True\")\n",
    "# df.info()\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/lux-org/lux-datasets/master/data/college.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "974ae8e5a713d00cb6495ce439c330db6dbba615c0d66e94baa213930f628eb5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
